import { NextRequest, NextResponse } from "next/server";
import { aiModelConfigService } from "@/lib/services/ai-model-config-service";
import { decrypt } from "@/lib/utils/encryption-utils";
import { getApiEndpointAndHeaders, AIModelConfig } from "@/lib/services/ai-service"; // Assuming AIModelConfig is exported, removed isGeminiModel

export const dynamic = "force-dynamic";
export const runtime = "nodejs";
export const maxDuration = 60;

// Define message structure for OpenAI-compatible models
interface OpenAIMessage {
  role: "system" | "user" | "assistant";
  content: string;
}

export async function POST(request: NextRequest): Promise<NextResponse> {
  try {
    const formData = await request.formData();
    const prompt = formData.get("prompt")?.toString();
    const systemPrompt = formData.get("systemPrompt")?.toString();
    const modelConfigId = formData.get("modelConfigId")?.toString();

    if (!prompt) {
      return NextResponse.json({ error: "è¯·æä¾›æç¤ºè¯ (prompt)" }, { status: 400 });
    }

    console.log("âœ¨ [Reasoning API] å¤„ç†æ¨ç†è¯·æ±‚:", {
      promptLength: prompt.length,
      hasSystemPrompt: !!systemPrompt,
      providedModelId: modelConfigId,
    });

    // 1. Get Model Configuration
    let modelConfig: AIModelConfig | null = null;
    if (modelConfigId) {
      modelConfig = await aiModelConfigService.getConfigById(modelConfigId);
      if (!modelConfig) {
        console.log(`âš ï¸ [Reasoning API] æœªæ‰¾åˆ°æŒ‡å®šæ¨¡å‹é…ç½® (ID: ${modelConfigId})ï¼Œå°è¯•é»˜è®¤æ¨ç†æ¨¡å‹ã€‚`);
      }
    }

    if (!modelConfig) {
      modelConfig = await aiModelConfigService.getDefaultReasoningConfig();
      if (!modelConfig) {
        console.log("âš ï¸ [Reasoning API] æœªæ‰¾åˆ°é»˜è®¤æ¨ç†æ¨¡å‹é…ç½®ï¼Œå°è¯•é»˜è®¤è¯­è¨€æ¨¡å‹ã€‚");
        modelConfig = await aiModelConfigService.getDefaultConfig(); // Fallback to default language model
      }
    }

    if (!modelConfig) {
      return NextResponse.json({ error: "æœªæ‰¾åˆ°å¯ç”¨çš„AIæ¨¡å‹é…ç½®" }, { status: 500 });
    }

    console.log("âœ¨ [Reasoning API] ä½¿ç”¨æ¨¡å‹é…ç½®:", {
      id: modelConfig.id,
      name: modelConfig.name,
      model: modelConfig.model,
      type: modelConfig.type,
      baseURL: modelConfig.baseURL,
    });

    // 2. Prepare for AI Call
    const apiKey = await decrypt(modelConfig.apiKey);
    if (!apiKey) {
        return NextResponse.json({ error: "æ— æ³•è§£å¯†APIå¯†é’¥" }, { status: 500 });
    }
    
    const activeModelConfig = { ...modelConfig, apiKey };

    // getApiEndpointAndHeaders will default to OpenAI-compatible structure
    const { endpoint, headers } = getApiEndpointAndHeaders(activeModelConfig);

    // Construct messages for OpenAI-compatible payload
    const messages: OpenAIMessage[] = [];
    if (systemPrompt) {
      messages.push({ role: "system", content: systemPrompt });
    }
    messages.push({ role: "user", content: prompt });
    
    const requestBody = {
      model: activeModelConfig.model,
      messages: messages,
      stream: true,
      temperature: activeModelConfig.temperature ?? 0.7,
    };

    console.log("âœ¨ [Reasoning API] å‘é€è¯·æ±‚åˆ° (OpenAI-compatible assumed):", endpoint);

    // 3. Make the streaming call
    const aiResponse = await fetch(endpoint, {
      method: "POST",
      headers: headers,
      body: JSON.stringify(requestBody),
    });

    if (!aiResponse.ok) {
      const errorText = await aiResponse.text();
      console.error(`ğŸ”´ [Reasoning API] AI provider APIè¯·æ±‚å¤±è´¥ (${aiResponse.status}):`, errorText);
      return NextResponse.json(
        { error: `AI providerè¯·æ±‚å¤±è´¥: ${aiResponse.status} ${errorText}` },
        { status: aiResponse.status }
      );
    }

    if (!aiResponse.body) {
      return NextResponse.json({ error: "AI providerå“åº”ä¸­æ²¡æœ‰body" }, { status: 500 });
    }

    // 4. Stream the response back to the client
    const stream = aiResponse.body;
    
    return new NextResponse(stream, {
      headers: {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
      },
    });

  } catch (error) {
    console.error("ğŸ”´ [Reasoning API] å†…éƒ¨æœåŠ¡å™¨é”™è¯¯:", error);
    return NextResponse.json(
      { error: error instanceof Error ? error.message : "å¤„ç†æ¨ç†è¯·æ±‚æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯" },
      { status: 500 }
    );
  }
} 